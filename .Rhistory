library("dplyr")
library("tidytext")
library("tidyverse")
# skip_empty_rows = true elimina las filas en blanco
# si fuera false las rellena con NA
pdf_cmf <- read_lines("C:\\Users\\panch\\Desktop\\python\\PRACTICA\\out_text.txt", skip_empty_rows = TRUE)
# skip_empty_rows = true elimina las filas en blanco
# si fuera false las rellena con NA
pdf_cmf <- read_lines("C:\\Users\\panch\\Desktop\\python\\PRACTICA\\Practica_Semana_5\\out_text.txt", skip_empty_rows = TRUE)
# largo del pdf
length(pdf_cmf)
#Convertimos el vector de caracteres en un dataframe con
# las variables: nro línea y texto
pdf_df <- tibble(parrafo = seq_along(pdf_cmf),texto = pdf_cmf)
str(pdf_df)
# tokenizar
pdf_pal <- pdf_df %>% unnest_tokens(palabra, texto)
head(pdf_pal, n=200)
# frecuencia absoluta
pdf_freq_abs <- pdf_pal %>% count(palabra, sort=TRUE)
head(pdf_freq_abs)
# frecuencia relativa
pdf_freq_rel <- pdf_pal %>% count(palabra, sort = TRUE) %>% mutate(relativa = n / sum(n))
head(pdf_freq_rel)
# limpiar palabras
stopwords <- get_stopwords("es")
stopwords <- stopwords %>% rename(palabra = word)
# eliminan las palabras inutiles
pdf_limp <- pdf_pal %>%
anti_join(stopwords)
# reordena el df
pdf_filtrado <- pdf_limp %>% count(palabra, sort = T) %>%
filter(n > 1) %>% mutate(palabra = reorder(palabra, n))
head(pdf_filtrado)
# frecuencia absoluta limpia
pdf_freq_abs <- pdf_limp %>% count(palabra, sort=TRUE)
head(pdf_freq_abs)
# frecuencia relativa limpia
pdf_freq_rel <- pdf_limp %>% count(palabra, sort = TRUE) %>% mutate(relativa = n / sum(n))
head(pdf_freq_rel)
# Se convierte todo el texto a minúsculas
palabra <- tolower(pdf_limp$palabra)
# Eliminación de páginas web (palabras que empiezan por "http." seguidas
# de cualquier cosa que no sea un espacio)
palabra <- str_replace_all(palabra,"http\\S*", "")
# Eliminación de signos de puntuación
palabra <- str_replace_all(palabra,"[[:punct:]]", " ")
# Eliminación de números
palabra <- str_replace_all(palabra,"[[:digit:]]", " ")
# Eliminación de espacios en blanco múltiples
palabra <- str_replace_all(palabra,"[\\s]+", " ")
df <- as_tibble(palabra)
df[ df == " "] <- "leo_messi"
df$value[df$value == " "] <- "leo_messi"
View(df)
df$value <- df$value[df$value!="leo_messi",]
df$value <- df$value [df$value!="leo_messi",]
df$value <-df$value [df$value!="leo_messi",]
df <- df[!"leo_messi"(df$value),]
df$value <- apply(df$value, 1, function(row) all(row !="leo_messi" ))
df$value <- apply(df$value, 1, function(row) all(row !=="leo_messi" ))
df$value <- apply(df$value, 1, function(row) all(row !== "leo_messi" ))
df <-df[df$value!="leo_messi",]
View(df)
df <-df[df$value!="n",]
# frecuencia absoluta limpia
pdf_freq_abs <- df$value %>% count(palabra, sort=TRUE)
# frecuencia absoluta limpia
pdf_freq_abs <- df %>% count(palabra, sort=TRUE)
# frecuencia absoluta limpia
pdf_freq_abs <- df %>% count(value, sort=TRUE)
head(pdf_freq_abs)
# frecuencia relativa limpia
pdf_freq_rel <- df %>% count(value, sort = TRUE) %>% mutate(relativa = n / sum(n))
head(pdf_freq_rel)
library("tm")
library("wordcloud")  # para graficar nubes de palabras.
library("NLP")
library("tm") # específico para minería de textos
library("RcolorBrewer")
#===========================================================================================#
## ANALISIS DE TEXTO ##
#===========================================================================================#
install.packages("RcolorBrewer")
#===========================================================================================#
## ANALISIS DE TEXTO ##
#===========================================================================================#
install.packages("RColorBrewer")
library("RColorBrewer") # wordcloud requiere RcolorBrewer
library("wordcloud")  # para graficar nubes de palabras.
library("ggplot2")
library("dplyr")
library("readr")
install.packages("cluster")
library("cluster")
library("SnowballC")
diez <- rep(1:ceiling(length(pdf_cmf)/10), each = 10)
# se deja el vector con n° de elementos iguales al n° de obs
diez <- diez[1:length(pdf_cmf)]
# se crea el df con una id de 10 en 10
pdf_text <- cbind(diez, pdf_cmf) %>% data.frame()
pdf_text <- pdf_text %>% select(pdf_cmf) %>% as.matrix
dim(pdf_text)
### limpieza
# elimina saltos de linea y tabulaciones
pdf_text <- gsub("[[:cntrl:]]", " ", pdf_text)
# pasa a minuscula
pdf_text <- tolower(pdf_text)
# pasa a minuscula
pdf_text <- tolower(pdf_text)
# pasa a minuscula
pdf_text <- tolower(pdf_text)
# stopword
pdf_text <- removeWords(pdf_text, words = stopwords("spanish"))
install.packages("RWeka")
install.packages("clValid")
install.packages("dendextend")
library("RWeka")      # collection of machine learning algorithms
library("dendextend") # Dendogram (hierarchical clustering)
library("clValid")    # Calculating Dunn index
# Creating Document Term Natrix
DTM = DocumentTermMatrix(df)
